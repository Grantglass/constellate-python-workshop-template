{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e89c5b3",
      "metadata": {
        "id": "3e89c5b3"
      },
      "source": [
        "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
        "\n",
        "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
        "\n",
        "Created by [Grant Glass](https://glassgrant.com) for the 2022 Text Analysis Pedagogy Institute, with support from the [National Endowment for the Humanities](https://neh.gov), [JSTOR Labs](https://labs.jstor.org/), and [University of Arizona Libraries](https://new.library.arizona.edu/).\n",
        "\n",
        "For questions/comments/improvements, email grantg@live.unc.edu<br />\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f932d1",
      "metadata": {
        "id": "68f932d1"
      },
      "source": [
        "# Machine Learning\n",
        "\n",
        "This is lesson `1` of 3 in the educational series on `Machine Learning`. This notebook is intended `to teach the basics of machine learning and introduce the concepts of:\n",
        "1) What is Machine Learning?<br>\n",
        "2) What is a Statistical Model?<br>\n",
        "3) A framework for understanding ML<br>\n",
        "4) Simple Example of ML <br> \n",
        "\n",
        "**Audience:** `Teachers` / `Learners` / `Researchers`\n",
        "\n",
        "**Use case:** `Tutorial`\n",
        "\n",
        "A tutorial is a carefully constructed example that takes the user by the hand through a series of steps to learn how a process works. Tutorials often use \"toy\" (or at least carefully constrained) examples that give reliable, accurate, and repeatable results every time.\n",
        "\n",
        "**Difficulty:** `Intermediate`\n",
        "\n",
        "\n",
        "`Intermediate assumes users are familiar with Python and have been programming for 6+ months. Code makes up a larger part of the notebook and basic concepts related to Python are not explained.`\n",
        "\n",
        "\n",
        "**Completion time:** `90 minutes`\n",
        "\n",
        "**Knowledge Required:** \n",
        "```\n",
        "* Python basics (variables, flow control, functions, lists, dictionaries)\n",
        "* Object-oriented programming (classes, instances, inheritance)\n",
        "* Regular Expressions (`re`, character classes)\n",
        "\n",
        "```\n",
        "\n",
        "**Knowledge Recommended:**\n",
        "```\n",
        "* Basic file operations (open, close, read, write)\n",
        "* Data cleaning with `Pandas`\n",
        "```\n",
        "\n",
        "**Learning Objectives:**\n",
        "After this lesson, learners will be able to:\n",
        "```\n",
        "1. Describe and implement an XXXX for XXXX\n",
        "2. Convert XXXX into XXXX for the purpose of XXXX\n",
        "3. Develop a workflow in order to XXXX\n",
        "4. Be familiar with XXXXX resources for pursuing the topic\n",
        "```\n",
        "**Research Pipeline:**\n",
        "```\n",
        "1. Research steps before this notebook\n",
        "2. **The skills in this notebook**\n",
        "3. Steps after this notebook\n",
        "4. Final steps\n",
        "```\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157c0555",
      "metadata": {
        "id": "157c0555"
      },
      "source": [
        "# Required Python Libraries\n",
        "* [Pandas](https://pandas.pydata.org/) for manipulating and cleaning data.\n",
        "* [Sklearn](https://scikit-learn.org/stable/) for machine learning.\n",
        "* [NLTK](https://www.nltk.org) for processing text.\n",
        "* [RE](https://docs.python.org/3/library/re.html) for finding patterns in our text, usually for clean-up or search.\n",
        "* [NUMPY](https://numpy.org) for calulcating complex equations (like precision and recall)\n",
        "* [SEABORN](https://seaborn.pydata.org) visualization library.  \n",
        "\n",
        "\n",
        "## Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e8a220f5",
      "metadata": {
        "id": "e8a220f5"
      },
      "outputs": [],
      "source": [
        "### Install Libraries ###\n",
        "\n",
        "# Library for Importing CSV file into a Dataframe\n",
        "import pandas as pd\n",
        "# Library to split the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Libraries to process section_text Tokenize=find words, Stopwords=remove stopwords, Regular Expression=remove non-word characters, Lemmatize text\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# A transformer LengthExtractor to extract length of each sentences in the section_text\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "#Model Tuning Libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Evaluation Libraries\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Allows the use of display() for DataFrames\n",
        "from IPython.display import display\n",
        "# Pretty display for notebooks\n",
        "%matplotlib inline\n",
        "\n",
        "#Ignore warnings = clean notebook\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grab NLTK (Natural Language Tool Kit) libraries\n",
        "#Stopwords (words we want to ignore)\n",
        "nltk.download('stopwords')\n",
        "#Punkt is a tokenizer that divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences. \n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw-PpPASg1fe",
        "outputId": "c2a59023-9188-488a-ce67-9f1dc9f112a2"
      },
      "id": "Dw-PpPASg1fe",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dedd148",
      "metadata": {
        "id": "8dedd148"
      },
      "source": [
        "# Required Data\n",
        "\n",
        "**Data Title**\n",
        "* training_set_v2.csv\n",
        "\n",
        "**Data Format:** \n",
        "* Comma-separated values  (.csv)\n",
        "\n",
        "**Data Source:**\n",
        "* [On the Books Project](https://onthebooks.lib.unc.edu)\n",
        "\n",
        "**Data Quality/Bias:**\n",
        "`The training set was created by using multiple sources: [1] Murray, Pauli. 1951. States’ Laws on Race and Color: And Appendices Containing International Documents, Federal Laws and Regulations, Local Ordinances and Charts. Cincinnati: Woman’s Division of Christian Service, Board of Missions and Church Extension, Methodist Church. [2] Paschal, Richard. 2020. Jim Crow in North Carolina The Legislative Program from 1865 to 1920. Durham: Carolina Academic Press. [3] A random sample of North Carolina laws enacted between 1866-1967 were assessed by scholars William Sturkey and Kimber Thomas to be either \"Jim Crow\" or \"Not Jim Crow\". [4] Team member James Dick reviewed the laws for consistency between the scholars' assessments.`\n",
        "\n",
        "**Data Description:**\n",
        "\n",
        "`This lesson uses the training set data in csv format from` [On the Books](https://cdr.lib.unc.edu/concern/data_sets/6q182v788?locale=en)\n",
        "\n",
        "## Loading Required Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv('training_set_v2.csv')"
      ],
      "metadata": {
        "id": "bqGU2407kGZn"
      },
      "id": "bqGU2407kGZn",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVa99S5vmCvU",
        "outputId": "e9526bdb-63d2-4ed9-abef-382adfc0fa2f"
      },
      "id": "jVa99S5vmCvU",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1785 entries, 0 to 1784\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            1785 non-null   object\n",
            " 1   source        1785 non-null   object\n",
            " 2   jim_crow      1785 non-null   int64 \n",
            " 3   type          1785 non-null   object\n",
            " 4   chapter_num   1785 non-null   int64 \n",
            " 5   section_num   1785 non-null   int64 \n",
            " 6   chapter_text  1785 non-null   object\n",
            " 7   section_text  1785 non-null   object\n",
            "dtypes: int64(3), object(5)\n",
            "memory usage: 111.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "4ZDrbA88nvyd",
        "outputId": "c6162c43-fd5e-48dd-af6b-79fb4b04838a"
      },
      "id": "4ZDrbA88nvyd",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id  source  jim_crow          type  chapter_num  \\\n",
              "0  1947_session laws_979_2  murray         1  session laws          978   \n",
              "1   1935_public laws_423_3  murray         1   public laws          422   \n",
              "2  1933_public laws_173_26  murray         1   public laws          172   \n",
              "3   1927_public laws_163_5  murray         1   public laws          162   \n",
              "4   1927_public laws_163_4  murray         1   public laws          162   \n",
              "\n",
              "   section_num                                       chapter_text  \\\n",
              "0            1  CHAPTER 978 AN ACT AUTHORIZING THE MEMBERS OF ...   \n",
              "1            2  CHAPTER 422 AN ACT TO PROVIDE A RENTAL SYSTEM ...   \n",
              "2           25  CHAPTER 172 AN ACT TO AMEND CHAPTER TWO, PUBLI...   \n",
              "3            4  CHAPTER 162 AN ACT RELATING TO THE ORGANIZATIO...   \n",
              "4            3  CHAPTER 162 AN ACT RELATING TO THE ORGANIZATIO...   \n",
              "\n",
              "                                        section_text  \n",
              "0  Subject only to restrictions and conditions no...  \n",
              "1  Powers and duties of Commission. The said Text...  \n",
              "2  The Commission shall provide separate sleeping...  \n",
              "3  That the said corporation shall receive, train...  \n",
              "4  That the five members of said Board of Directo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0acc453e-2163-4cad-aba4-ddee33d327c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>source</th>\n",
              "      <th>jim_crow</th>\n",
              "      <th>type</th>\n",
              "      <th>chapter_num</th>\n",
              "      <th>section_num</th>\n",
              "      <th>chapter_text</th>\n",
              "      <th>section_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1947_session laws_979_2</td>\n",
              "      <td>murray</td>\n",
              "      <td>1</td>\n",
              "      <td>session laws</td>\n",
              "      <td>978</td>\n",
              "      <td>1</td>\n",
              "      <td>CHAPTER 978 AN ACT AUTHORIZING THE MEMBERS OF ...</td>\n",
              "      <td>Subject only to restrictions and conditions no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1935_public laws_423_3</td>\n",
              "      <td>murray</td>\n",
              "      <td>1</td>\n",
              "      <td>public laws</td>\n",
              "      <td>422</td>\n",
              "      <td>2</td>\n",
              "      <td>CHAPTER 422 AN ACT TO PROVIDE A RENTAL SYSTEM ...</td>\n",
              "      <td>Powers and duties of Commission. The said Text...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1933_public laws_173_26</td>\n",
              "      <td>murray</td>\n",
              "      <td>1</td>\n",
              "      <td>public laws</td>\n",
              "      <td>172</td>\n",
              "      <td>25</td>\n",
              "      <td>CHAPTER 172 AN ACT TO AMEND CHAPTER TWO, PUBLI...</td>\n",
              "      <td>The Commission shall provide separate sleeping...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1927_public laws_163_5</td>\n",
              "      <td>murray</td>\n",
              "      <td>1</td>\n",
              "      <td>public laws</td>\n",
              "      <td>162</td>\n",
              "      <td>4</td>\n",
              "      <td>CHAPTER 162 AN ACT RELATING TO THE ORGANIZATIO...</td>\n",
              "      <td>That the said corporation shall receive, train...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1927_public laws_163_4</td>\n",
              "      <td>murray</td>\n",
              "      <td>1</td>\n",
              "      <td>public laws</td>\n",
              "      <td>162</td>\n",
              "      <td>3</td>\n",
              "      <td>CHAPTER 162 AN ACT RELATING TO THE ORGANIZATIO...</td>\n",
              "      <td>That the five members of said Board of Directo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0acc453e-2163-4cad-aba4-ddee33d327c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0acc453e-2163-4cad-aba4-ddee33d327c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0acc453e-2163-4cad-aba4-ddee33d327c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f53edaa2",
      "metadata": {
        "id": "f53edaa2"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "```\n",
        "Introduce the lesson topic. Answer questions such as:\n",
        "* Why is it useful? \n",
        "* Why should we learn it? \n",
        "* Who might use it? \n",
        "* Where has it been used by scholars/industry?\n",
        "* What do we need to do it?\n",
        "* What subjects are included in the notebooks?\n",
        "* What is not in this notebook? Where should we look for it?\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No Code Example of Machine Learning\n",
        "\n",
        "Head to the Google Teachable Machine Website: https://teachablemachine.withgoogle.com\n",
        "\n",
        "The Teachable Machine website provides an easy to use interface for training image, sound, and pose classification models. No login is required to get started. Training data files can be loaded directly from your computer or from your computer’s webcam or microphone. Models can be exported to use in other projects, and the FAQ (https://cloud.google.com/inclusive-ml/) includes links to read more about fairness and inclusion in ML.\n",
        "\n",
        "Take a look at this project involving training a model to detect how ripe a piece of fruit is: https://medium.com/@warronbebster/teachable-machine-tutorial-bananameter-4bfffa765866\n",
        "\n",
        "\n",
        "How do you think the computer figures out ripeness?\n",
        "\n",
        "What exactly are we teaching the machine?\n",
        "\n",
        "What other humanistic data could we use for this type of machine learning?"
      ],
      "metadata": {
        "id": "PPNnyFk_mk--"
      },
      "id": "PPNnyFk_mk--"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Concept One - What is MACHINE LEARNING?"
      ],
      "metadata": {
        "id": "f-1wkSIbn3ED"
      },
      "id": "f-1wkSIbn3ED"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning is a field of study which harnesses principles of computer science and statistics to create statistical models. These models are generally used to do two things:\n",
        "\n",
        "1. Prediction: make predictions about the future based on data about the past\n",
        "2. Inference: discover patterns in data\n",
        "\n",
        "What is the difference between this and AI?\n",
        "There is no universally agreed upon distinction between ML and artificial intelligence (AI). AI usually concentrates on programming computers to make decisions (based on ML models and sets of logical rules), whereas ML focuses more on making predictions about the future. They are highly interconnected fields, and, for most non-technical purposes, they are the same."
      ],
      "metadata": {
        "id": "eRNB4Cp_oRoD"
      },
      "id": "eRNB4Cp_oRoD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Concept Two - What is A STATISTICAL MODEL?"
      ],
      "metadata": {
        "id": "zPv-yInsoqeJ"
      },
      "id": "zPv-yInsoqeJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Models:** Teaching a computer to make predictions involves feeding data into machine learning models, which are representations of how the world supposedly works. If I tell a statistical model that the world works a certain way (say, for example, that two story homes are more expensive than one story homes), then this model can then tell me what be more expensive, a ranch style home or a cape cod. \n",
        "\n",
        "What does a model actually look like? Surely the concept of a model makes sense in the abstract, but knowing this is just half the battle. You should also know how it’s represented inside of a computer, or what it would look like if you wrote it down on paper.\n",
        "\n",
        "A model is just a mathematical function, which is merely a relationship between a set of inputs and a set of outputs. Here’s an example:\n",
        "\n",
        "f(x) = x²\n",
        "\n",
        "This is a function that takes as input a number and returns that number squared. So, f(1) = 1, f(2) = 4, f(3) = 9.\n",
        "\n",
        "Let’s briefly return to the example of the model that predicts home price from home stories. I may believe, based on what I’ve seen in the world, that given a home's price is, on average, equal to the house's stories times 100,000. \n",
        "\n",
        "This model can be represented mathematically as follows:\n",
        "\n",
        "Price = Stories × $100,000\n",
        "\n",
        "In other words, income is a function of stories.\n",
        "\n",
        "**Here’s the main point:** Machine learning refers to a set of techniques for estimating functions (like the one involving income) based on datasets (pairs of heights and their associated incomes). These functions, which are called models, can then be used for predictions of future data.\n",
        "\n",
        "**Algorithms:** These functions are estimated using algorithms. In this context, an algorithm is a predefined set of steps that takes as input a bunch of data and then transforms it through mathematical operations. You can think of an algorithm like a recipe — first do this, then do that, then do this. Done.\n",
        "Machine learning of all types uses models and algorithms as its building blocks to make predictions and inferences about the world.\n",
        "Now I’ll show you how models actually work by breaking them apart, component by component. This next part is important."
      ],
      "metadata": {
        "id": "ShkIGUpUowlA"
      },
      "id": "ShkIGUpUowlA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Concept Three - A Machine Learning Framework"
      ],
      "metadata": {
        "id": "-ynB4UjipF-z"
      },
      "id": "-ynB4UjipF-z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inputs:** Statistical models learn from the past, formatted as structured tables of data (called **training data**). These datasets — such as those you might find in Excel sheets — tend to be formatted in a very structured, easy-to-understand way: each row in the dataset represents an individual **observation,** also called a datum or measurement, and each column represents a different **feature**, also called a predictor, of an observation.\n",
        "\n",
        "For example, you might imagine a dataset about people, in which each row represents a different person, and each column represents a different feature about that person: profession, age, income, etc.\n",
        "\n",
        "Most traditional models accept data formatted in the way I’ve just described. We call this structured data.\n",
        "\n",
        "Because one common goal of ML is to make predictions, training data also includes a column containing the data you want to predict. This feature is called the response variable (or output variable, or dependent variable) and looks just like any other feature in the table.\n",
        "\n",
        "Most common statistical models are constructed using a technique called supervised learning, which uses data that includes a response variable to make predictions or do inference. There is also a branch of ML called unsupervised learning, which doesn’t require a response variable and which is generally used just to find interesting patterns between variables (this pattern-finding process is known as inference). It is just as important as supervised learning, but it is usually much harder to understand and also less common in practice. This document won’t talk much about the latter subfield. The takeaway from this paragraph is simply that there are two “types” of learning, and that supervised learning is more common.\n",
        "\n",
        "\n",
        "Model selection: We have our data, and we’ve decided that there’s probably a relationship between our predictors and our response. We’re ready to make predictions.\n",
        "\n",
        "As an aside, we don’t actually need to know if there’s a relationship between these variables. We could, in fact, just throw all of our data into an algorithm and see if the resulting model is able to make valid predictions.\n",
        "Now we need to pick which model to use. Naturally, there are many different types of models which explain how the data actually works, and we’d like to choose the one that most accurately describes the relationship between the predictors and the response variable.\n",
        "\n",
        "Models generally fall into one of two categories:\n",
        "**Regression models**, which are used when the response variable (i.e. the variable that you’re predicting) is continuous. For example, height, age, and income are all continuous. That is, they can be placed and ordered on a number line.\n",
        "**Classification models**, which are used for categorical data — that is, data that doesn’t have a numerical ordering. For example, you may want to predict, based on an image of a flower, the species of that flower. Or you may want to predict whether a student is a psychology major or a math major.\n",
        "The first step in picking a model is deciding whether or not your response variable is quantitative or categorical.\n",
        "\n",
        "\n",
        "Why is model selection an important concept for non-technical people? \n",
        "\n",
        "Well, if a model is chosen poorly, then its predictions will be inaccurate!\n"
      ],
      "metadata": {
        "id": "6JLUvEAapWZ1"
      },
      "id": "6JLUvEAapWZ1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Machine Learning with the On the Books Project"
      ],
      "metadata": {
        "id": "60Bl-ickp3tC"
      },
      "id": "60Bl-ickp3tC"
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "pFaCFJ6ZqGlp",
        "outputId": "a029bc75-a9a8-42c6-d03b-ae7de13f29c7"
      },
      "id": "pFaCFJ6ZqGlp",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           id           source  jim_crow          type  \\\n",
              "490  1959_session laws_1066_3  project experts         0  session laws   \n",
              "\n",
              "     chapter_num  section_num  \\\n",
              "490         1065            2   \n",
              "\n",
              "                                          chapter_text  \\\n",
              "490  CHAPTER 1065 AN ACT TO AUTHORIZE THE ISSUANCE ...   \n",
              "\n",
              "                                          section_text  \n",
              "490  At the close of the polls the election officer...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c281fdb5-141b-42c0-8f66-17c75a523f1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>source</th>\n",
              "      <th>jim_crow</th>\n",
              "      <th>type</th>\n",
              "      <th>chapter_num</th>\n",
              "      <th>section_num</th>\n",
              "      <th>chapter_text</th>\n",
              "      <th>section_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>1959_session laws_1066_3</td>\n",
              "      <td>project experts</td>\n",
              "      <td>0</td>\n",
              "      <td>session laws</td>\n",
              "      <td>1065</td>\n",
              "      <td>2</td>\n",
              "      <td>CHAPTER 1065 AN ACT TO AUTHORIZE THE ISSUANCE ...</td>\n",
              "      <td>At the close of the polls the election officer...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c281fdb5-141b-42c0-8f66-17c75a523f1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c281fdb5-141b-42c0-8f66-17c75a523f1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c281fdb5-141b-42c0-8f66-17c75a523f1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before the file was imported, we performed simple preprocessing on the text (these are outlined in the code bellow):\n",
        "* Replaced hyphenated and line broken words with unbroken words.\n",
        "* Removed section numbering from the law text (\"section_text\").\n",
        "* We used session or volume identified (\"csv\") information to extract a numeric year.  In the case of multi-year volumes (e.g. 1956-1957) the earlier year was used."
      ],
      "metadata": {
        "id": "kJ2U5itlqajw"
      },
      "id": "kJ2U5itlqajw"
    },
    {
      "cell_type": "code",
      "source": [
        "#Fix hyphenated words\n",
        "#data[\"chapter_text\"] = data.text.str.replace(r\"-[ \\|]+(?P<letter>[a-zA-Z])\",repl).astype(\"str\")\n",
        "#data[\"section_text\"] = data.section_text.str.replace(r\"-[ \\|]+(?P<letter>[a-zA-Z])\",repl).astype(\"str\")\n",
        "#data[\"section_text\"] = [re.sub(r'- *\\n+(\\w+ *)', r'\\1\\n',r) for r in data[\"section_text\"]]\n",
        "\n",
        "\n",
        "#Remove section titles (e.g. \"Sec. 1\") from law text.\n",
        "#data[\"start\"] = data.section_raw.str.len().fillna(0).astype(\"int\")\n",
        "#data[\"section_text\"] = data.apply(lambda x: x['section_text'][(x[\"start\"]):], axis=1).str.strip()"
      ],
      "metadata": {
        "id": "znuqp4RKqd6G"
      },
      "id": "znuqp4RKqd6G",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "2r3p410hqpPV"
      },
      "id": "2r3p410hqpPV"
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['jim_crow'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi9TD8fKqr_W",
        "outputId": "d36b916f-fb6c-47b0-d7f7-3e84461fdda8"
      },
      "id": "Pi9TD8fKqr_W",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1273\n",
              "1     512\n",
              "Name: jim_crow, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of records\n",
        "n_records = len(dataframe.index)\n",
        "\n",
        "# jim crow laws\n",
        "jim_crow_laws = len(dataframe[dataframe.jim_crow == 1])\n",
        "\n",
        "# non-jim crow laws\n",
        "regular_laws = len(dataframe[dataframe.jim_crow == 0])\n",
        "\n",
        "# Percent of Jim Crow Laws\n",
        "jimcrow_percent = (jim_crow_laws / float(n_records)) * 100\n",
        "\n",
        "# Print the results\n",
        "print(\"Total number of records: {}\".format(n_records))\n",
        "print(\"Jim Crow Laws: {}\".format(jim_crow_laws))\n",
        "print(\"Non-Jim Crow Laws: {}\".format(regular_laws))\n",
        "print(\"Percentage of Jim Crow Laws: {}%\".format(jimcrow_percent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr8WhmWqq1TN",
        "outputId": "3afdf28b-0fd8-473f-f9df-2cb089d70735"
      },
      "id": "kr8WhmWqq1TN",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of records: 1785\n",
            "Jim Crow Laws: 512\n",
            "Non-Jim Crow Laws: 1273\n",
            "Percentage of Jim Crow Laws: 28.68347338935574%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Data\n",
        "Before data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured — this is typically known as **preprocessing**. Fortunately, for this dataset, there are no invalid or missing entries we must deal with, however, there are some qualities about certain features that must be adjusted. This preprocessing can help tremendously with the outcome and predictive power of nearly all learning algorithms."
      ],
      "metadata": {
        "id": "8w54IsrWrEyX"
      },
      "id": "8w54IsrWrEyX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and target label\n",
        "features = dataframe['section_text']\n",
        "target = dataframe['jim_crow']"
      ],
      "metadata": {
        "id": "60RWN-FsrIlE"
      },
      "id": "60RWN-FsrIlE",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shuffle and Split Data\n",
        "Now all _categorical variables_ have been converted into numerical features, and all numerical features have been normalized. As always, we will now split the data (both features and their labels) into training and test sets. 80% of the data will be used for training and 20% for testing.\n",
        "\n",
        "Run the code cell below to perform this split."
      ],
      "metadata": {
        "id": "2dNaeYS5rQzW"
      },
      "id": "2dNaeYS5rQzW"
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Show the results of the split\n",
        "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwYQSeM0rRn9",
        "outputId": "4f1f3bef-9f80-413e-852d-1af2bdc81087"
      },
      "id": "nwYQSeM0rRn9",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set has 1428 samples.\n",
            "Testing set has 357 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "Tx1158kGrZlU"
      },
      "id": "Tx1158kGrZlU"
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Processing\n",
        "# extract the english stopwords and save it to a variable\n",
        "stopword = stopwords.words('english')\n",
        "# define regular expression to identify non-ascii characters in text\n",
        "non_ascii_regex = r'[^\\x00-\\x7F]+'\n",
        "def tokenize(text):\n",
        "        \n",
        "    # use library re to replace non ascii characters by a space\n",
        "    text = re.sub(non_ascii_regex, ' ', text)  \n",
        "\n",
        "    # use word_tokenize to tokenize the sentences\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # instantiate an object of class WordNetLemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # use a list comprehension to lemmatize the tokens and remove the the stopwords\n",
        "    clean_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopword]\n",
        "\n",
        "    # return the tokens\n",
        "    return clean_tokens"
      ],
      "metadata": {
        "id": "UlqqttsDraTK"
      },
      "id": "UlqqttsDraTK",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer of text = turning text into numbers"
      ],
      "metadata": {
        "id": "LgpBm-OHrkVG"
      },
      "id": "LgpBm-OHrkVG"
    },
    {
      "cell_type": "code",
      "source": [
        "# A transformer LengthExtractor to extract length of each sentences in the section_text and make that a feature\n",
        "class LengthExtractor(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def compute_length(self, text):\n",
        "        sentence_list = word_tokenize(text)\n",
        "        return len(sentence_list)\n",
        "    \n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_length = pd.Series(X).apply(self.compute_length)\n",
        "        return pd.DataFrame(X_length)"
      ],
      "metadata": {
        "id": "83fRvA3drkyx"
      },
      "id": "83fRvA3drkyx",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What does a transformer do?"
      ],
      "metadata": {
        "id": "z2NTuSscroob"
      },
      "id": "z2NTuSscroob"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# list of text documents\n",
        "text = [\"The quick red fox jumped over the lazy dog.\"]\n",
        "# create the transform\n",
        "vectorizer = CountVectorizer()\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(text)\n",
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "# encode document\n",
        "vector = vectorizer.transform(text)\n",
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(type(vector))\n",
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K-KjhyHrx4A",
        "outputId": "71b21cb8-71ca-4296-f6c7-9b48a9beb719"
      },
      "id": "5K-KjhyHrx4A",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 7, 'quick': 5, 'red': 6, 'fox': 1, 'jumped': 2, 'over': 4, 'lazy': 3, 'dog': 0}\n",
            "(1, 8)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "[[1 1 1 1 1 1 1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are 8 words in the vocab, and therefore encoded vectors have a length of 8.\n",
        "\n",
        "We can then see that the encoded vector is a sparse matrix. Finally, we can see an array version of the encoded vector showing a count of 1 occurrence for each word except the (index and id 7) that has an occurrence of 2"
      ],
      "metadata": {
        "id": "mXfFBwpgr5B3"
      },
      "id": "mXfFBwpgr5B3"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# list of text documents\n",
        "text = [\"The quick red fox jumped over the lazy dog.\", \"The dog.\", \"The fox\"]\n",
        "# create the transform\n",
        "vectorizer = TfidfVectorizer()\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(text)\n",
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.idf_)\n",
        "# encode document\n",
        "vector = vectorizer.transform([text[0]])\n",
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPBiSRmtr9CF",
        "outputId": "fd501d0c-6690-46a4-a2d0-91b8cb0feb90"
      },
      "id": "rPBiSRmtr9CF",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 7, 'quick': 5, 'red': 6, 'fox': 1, 'jumped': 2, 'over': 4, 'lazy': 3, 'dog': 0}\n",
            "[1.28768207 1.28768207 1.69314718 1.69314718 1.69314718 1.69314718\n",
            " 1.69314718 1.        ]\n",
            "(1, 8)\n",
            "[[0.27674503 0.27674503 0.36388646 0.36388646 0.36388646 0.36388646\n",
            "  0.36388646 0.42983441]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A vocabulary of 8 words is learned from the documents and each word is assigned a unique integer index in the output vector.\n",
        "The inverse document frequencies are calculated for each word in the vocabulary, assigning the lowest score of 1.0 to the most frequently observed word: “the” at index 7.\n",
        "Finally, the first document is encoded as an 8-element sparse array"
      ],
      "metadata": {
        "id": "E4fbZ-fTsDrG"
      },
      "id": "E4fbZ-fTsDrG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## Training our Model"
      ],
      "metadata": {
        "id": "wQkUvT09sKZ1"
      },
      "id": "wQkUvT09sKZ1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Training and Predicting Pipeline"
      ],
      "metadata": {
        "id": "Ods8HHEjsN1n"
      },
      "id": "Ods8HHEjsN1n"
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of Pipeline class\n",
        "pipeline = Pipeline([\n",
        "    \n",
        "        # create a FeatureUnion pipeline\n",
        "        ('features', FeatureUnion([\n",
        "\n",
        "            # add a pipeline element to extract features using CountVectorizer and TfidfTransformer\n",
        "            ('text_pipleline', Pipeline([\n",
        "                ('vect', CountVectorizer(decode_error = \"ignore\",\n",
        "                      min_df = 2, max_df = 1000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "            ])),\n",
        "            \n",
        "            # add the pipeline element - LengthExtractor to extract lenght of each sentence as feature\n",
        "            ('text_len', LengthExtractor()),\n",
        "        ])),\n",
        "\n",
        "        # use the predictor estimator RandomForestClassifier to train the model\n",
        "        ('dlf', RandomForestClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "Zc15U17BsTEx"
      },
      "id": "Zc15U17BsTEx",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction\n",
        "\n",
        "https://towardsdatascience.com/understanding-random-forest-58381e0602d2"
      ],
      "metadata": {
        "id": "wosrOXDksXwy"
      },
      "id": "wosrOXDksXwy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Supervised Learning Models\n",
        "**The following are some of the supervised learning models that are currently available in** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) **that you may choose from:**\n",
        "- Gaussian Naive Bayes (GaussianNB)\n",
        "- Decision Trees\n",
        "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
        "- K-Nearest Neighbors (KNeighbors)\n",
        "- Stochastic Gradient Descent Classifier (SGDC)\n",
        "- Support Vector Machines (SVM)\n",
        "- Logistic Regression"
      ],
      "metadata": {
        "id": "-IoxXC_Fsoh-"
      },
      "id": "-IoxXC_Fsoh-"
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the Model\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lLgJeHosat2",
        "outputId": "f541fb24-ca3d-4484-b447-8f53abaffa50"
      },
      "id": "9lLgJeHosat2",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('features',\n",
              "                 FeatureUnion(transformer_list=[('text_pipleline',\n",
              "                                                 Pipeline(steps=[('vect',\n",
              "                                                                  CountVectorizer(decode_error='ignore',\n",
              "                                                                                  max_df=1000,\n",
              "                                                                                  min_df=2)),\n",
              "                                                                 ('tfidf',\n",
              "                                                                  TfidfTransformer())])),\n",
              "                                                ('text_len',\n",
              "                                                 LengthExtractor())])),\n",
              "                ('dlf', RandomForestClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Model Evaluation"
      ],
      "metadata": {
        "id": "d7ezvp3TsgKz"
      },
      "id": "d7ezvp3TsgKz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is accuracy, precision, recall?\n",
        "\n",
        "** Accuracy ** measures how often the classifier makes the correct prediction. It’s the ratio of the number of correct predictions to the total number of predictions (the number of test data points).\n",
        "\n",
        "** Precision ** tells us what proportion of messages we classified as Jim Crow, actually were Jim Crow.\n",
        "It is a ratio of true positives(laws classified as Jim Crow, and which are actually Jim Crow) to all positives(all laws classified as Jim Crow, irrespective of whether that was the correct classificatio), in other words it is the ratio of\n",
        "\n",
        "`[True Positives/(True Positives + False Positives)]`\n",
        "\n",
        "** Recall(sensitivity)** tells us what proportion of laws that actually were Jim Crow were classified by us as Jim Crow.\n",
        "It is a ratio of true positives(laws classified as Jim Crow, and which are actually Jim Crow) to all the laws that were actually Crow, in other words it is the ratio of\n",
        "\n",
        "`[True Positives/(True Positives + False Negatives)]`\n",
        "\n",
        "These two metrics can be combined to get the F1 score, which is weighted average(harmonic mean) of the precision and recall scores. This score can range from 0 to 1, with 1 being the best possible F1 score(we take the harmonic mean as we are dealing with ratios). We can use **F-beta score** as a metric that considers both precision and recall:\n",
        "\n",
        "\n",
        "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
        "\n",
        "In particular, when $\\beta = 0.5$, more emphasis is placed on precision. This is called the **F$_{0.5}$ score** (or F-score for simplicity).\n",
        "\n",
        "Another Resource for understanding this report: https://medium.com/@kohlishivam5522/understanding-a-classification-report-for-your-machine-learning-model-88815e2ce397\n"
      ],
      "metadata": {
        "id": "DgwO0eS5s2pF"
      },
      "id": "DgwO0eS5s2pF"
    },
    {
      "cell_type": "code",
      "source": [
        "#Make Predictions on the Test Data\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "AcADh2e6s6WF"
      },
      "id": "AcADh2e6s6WF",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of labels\n",
        "labels = np.unique(y_pred)\n",
        "\n",
        "data = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "\n",
        "# use sns.heatmap on top of confusion_matrix to show the confusion matrix\n",
        "ax = sns.heatmap(df_cm,xticklabels=True, annot=True, fmt='.0f')\n",
        "ax.set(title=\"Overall\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "uceQPCPls-zg",
        "outputId": "7de530d6-6359-405d-a605-24a73e47fed6"
      },
      "id": "uceQPCPls-zg",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5, 1.0, 'Overall')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq8ewIxutDWp",
        "outputId": "2785cafa-4d45-4e79-8c53-de1bed55c3a9"
      },
      "id": "Eq8ewIxutDWp",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       262\n",
            "           1       0.95      0.95      0.95        95\n",
            "\n",
            "    accuracy                           0.97       357\n",
            "   macro avg       0.96      0.96      0.96       357\n",
            "weighted avg       0.97      0.97      0.97       357\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Predictor Performace\n",
        "* If we chose a model that always predicted if a law was jim crow, what would  that model's accuracy and F-score be on this dataset?\n",
        "\n",
        "** Please note ** that the the purpose of generating a naive predictor is simply to show what a base model without any intelligence would look like. In the real world, ideally your base model would be either the results of a previous model or could be based on a research paper upon which you are looking to improve. When there is no benchmark model set, getting a result better than random choice is a place you could start from.\n",
        "\n",
        "** NOTE: ** \n",
        "\n",
        "* When we have a model that always predicts '1' (i.e. there is always a jim crow law) then our model will have no True Negatives(TN) or False Negatives(FN) as we are not making any negative('0' value) predictions. Therefore our Accuracy in this case becomes the same as our Precision(True Positives/(True Positives + False Positives)) as every prediction that we have made with value '1' that should have '0' becomes a False Positive; therefore our denominator in this case is the total number of records we have in total. \n",
        "* Our Recall score(True Positives/(True Positives + False Negatives)) in this setting becomes 1 as we have no False Negatives."
      ],
      "metadata": {
        "id": "-xGoc3ketD_A"
      },
      "id": "-xGoc3ketD_A"
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Accuracy, Recall, Precision\n",
        "accuracy = (np.sum(target)) / ((np.sum(target)) + float(((target.count()) - np.sum(target))))\n",
        "recall = np.sum(target) / float((np.sum(target) + 0))\n",
        "precision = np.sum(target) / float(((np.sum(target) + ((target.count()) - np.sum(target)))))\n",
        "\n",
        "#Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
        "beta = 0.5\n",
        "fscore = (1+ beta**2) * (precision * recall) / ((beta ** 2 * precision) + recall)\n",
        "\n",
        "#Print the results \n",
        "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6217MKi3tGoA",
        "outputId": "79114991-e721-4512-b1b7-f712b4f5b8c4"
      },
      "id": "6217MKi3tGoA",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Predictor: [Accuracy score: 0.2868, F-score: 0.3346]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca42822",
      "metadata": {
        "id": "eca42822"
      },
      "source": [
        "# Exercises (Try your own model)\n",
        "\n",
        "`Now that you know how to train a basic model, try to use your own dataset.`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv('your_dataset.csv') #replace your_dataset.csv with your own file name"
      ],
      "metadata": {
        "id": "uHFAP-u3u5ep"
      },
      "id": "uHFAP-u3u5ep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and target label\n",
        "features = dataframe['text'] #this is the text in your csv your want to categorize or predict\n",
        "target = dataframe['label'] #this is your label in your csv you want to predict to"
      ],
      "metadata": {
        "id": "0_j9AhhpvEJr"
      },
      "id": "0_j9AhhpvEJr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Show the results of the split\n",
        "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
      ],
      "metadata": {
        "id": "5tSlkAruv2t9"
      },
      "id": "5tSlkAruv2t9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Processing\n",
        "# extract the english stopwords and save it to a variable\n",
        "stopword = stopwords.words('english')\n",
        "# define regular expression to identify non-ascii characters in text\n",
        "non_ascii_regex = r'[^\\x00-\\x7F]+'\n",
        "def tokenize(text):\n",
        "        \n",
        "    # use library re to replace non ascii characters by a space\n",
        "    text = re.sub(non_ascii_regex, ' ', text)  \n",
        "\n",
        "    # use word_tokenize to tokenize the sentences\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # instantiate an object of class WordNetLemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # use a list comprehension to lemmatize the tokens and remove the the stopwords\n",
        "    clean_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopword]\n",
        "\n",
        "    # return the tokens\n",
        "    return clean_tokens"
      ],
      "metadata": {
        "id": "X3ua-1odzOAI"
      },
      "id": "X3ua-1odzOAI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A transformer LengthExtractor to extract length of each sentences in the section_text and make that a feature\n",
        "class LengthExtractor(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def compute_length(self, text):\n",
        "        sentence_list = word_tokenize(text)\n",
        "        return len(sentence_list)\n",
        "    \n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_length = pd.Series(X).apply(self.compute_length)\n",
        "        return pd.DataFrame(X_length)"
      ],
      "metadata": {
        "id": "gcZnJljhzc5C"
      },
      "id": "gcZnJljhzc5C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of Pipeline class\n",
        "pipeline = Pipeline([\n",
        "    \n",
        "        # create a FeatureUnion pipeline\n",
        "        ('features', FeatureUnion([\n",
        "\n",
        "            # add a pipeline element to extract features using CountVectorizer and TfidfTransformer\n",
        "            ('text_pipleline', Pipeline([\n",
        "                ('vect', CountVectorizer(decode_error = \"ignore\",\n",
        "                      min_df = 2, max_df = 1000)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "            ])),\n",
        "            \n",
        "            # add the pipeline element - LengthExtractor to extract lenght of each sentence as feature\n",
        "            ('text_len', LengthExtractor()),\n",
        "        ])),\n",
        "\n",
        "        # use the predictor estimator RandomForestClassifier to train the model\n",
        "        ('dlf', RandomForestClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "MP72B02LwDg6"
      },
      "id": "MP72B02LwDg6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the Model\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "frTQLHmRwJnl"
      },
      "id": "frTQLHmRwJnl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of labels\n",
        "labels = np.unique(y_pred)\n",
        "\n",
        "data = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "\n",
        "# use sns.heatmap on top of confusion_matrix to show the confusion matrix\n",
        "ax = sns.heatmap(df_cm,xticklabels=True, annot=True, fmt='.0f')\n",
        "ax.set(title=\"Overall\")"
      ],
      "metadata": {
        "id": "JLxUDvtowMcS"
      },
      "id": "JLxUDvtowMcS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "H_9JVySNwPOn"
      },
      "id": "H_9JVySNwPOn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e42c9736",
      "metadata": {
        "id": "e42c9736"
      },
      "source": [
        "# Questions and Errors\n",
        "`Please Share any questions or troubles you have with the code in this google document`\n",
        "https://docs.google.com/document/d/10XQ9zn_IEQDWKq65LK9rUatvwZliTw71pTh1vXBYMF8/edit?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2368107",
      "metadata": {
        "id": "d2368107"
      },
      "source": [
        "# Living Bilbiography\n",
        "\n",
        "\n",
        "https://docs.google.com/document/d/13iyDS6R3keRxyJTrFOD42As6rEOg8vIdnhXyN21A6z4/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9c98f19",
      "metadata": {
        "id": "b9c98f19"
      },
      "source": [
        "# Next Lesson\n",
        "\n",
        "\n",
        "\n",
        "___\n",
        "[Proceed to next lesson: Course Machine Learning 2/3 ->](./day2_intro_to_ml.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "day1_intro_to_ml.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}